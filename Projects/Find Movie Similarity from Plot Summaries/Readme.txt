
Project Tools

In this project  , I used NLTK library for tokenization and stemming also together in texts and words  , 
KMeans Cluster Analysis to group each movie with  fitted matrix with TfidfVectorizer (with together tokenized and stemmed texts) , 
Lastly , calculating similarity distance  with the matrix above and also plotting dendrogram to show all similarities visually.
 

Project Description

Natural Language Processing (NLP) is an exciting field of study for data scientists where they develop algorithms that can make sense out of 
conversational language used by humans. In this Project, I will use NLP to find the degree of similarity between movies based on their plots 
available on IMDb and Wikipedia.The dataset contains the titles of the top 100 movies on IMDb as well as each movie's plot summary from both 
IMDb and Wikipedia.



Project Tasks

1. Import and observe dataset
2. Combine Wikipedia and IMDb plot summaries
3. Tokenization
4. Stemming
5. Club together Tokenize & Stem
6. Create TfidfVectorizer
7. Fit transform TfidfVectorizer
8. Import KMeans and create clusters
9. Calculate similarity distance
10. Import Matplotlib, Linkage, and Dendrograms
11. Create merging and plot dendrogram
12. Which movies are most similar?


